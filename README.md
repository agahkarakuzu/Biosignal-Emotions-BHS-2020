# Project Description BrainHack School 2020

![BrainHack School](bhs2020.png)

## Summary 

Biosignal processing for automatic emotion recognition using open data.

## Project definition 

### Background

Danielle:

 I’m a master’s student working on the development of a device for students on the autism spectrum. The project envisions a device that can address students’ auditory sensitivities by filtering out distressing classroom sounds in real-time. I plan to use machine learning techniques for the following 2 components of the project: 

 1.	Audio event classification for the detection of identified classroom sounds
 2.	Biosignal-based automatic emotion recognition for the detection of sound-induced distress

 Assuming that #2 is where I can make the most of the expertise of fellow BrainHack school participants, I thought I could focus on biosignal processing for automatic emotion recognition during the project weeks.

### Tools 

Tools and techniques we plan to use:
 1.	High-performance computing: Compute Canada
 2.	Preprocessing and feature extraction with Python
 3.	Data visualization with Python
 4.	GitHub
 5.	Python Virtual Environment

### Data 

So far, we have access to the following multi-modal emotion recognition databases: 

 - [The MAHNOB-HCI-Tagging database](https://mahnob-db.eu/hci-tagging/)
 - [DREAMER: A Database for Emotion Recognition through EEG and ECG Signals from Wireless Low-cost Off-the-Shelf Devices](https://ieeexplore.ieee.org/document/7887697)

### Deliverables

At the end of this project, we plan to complete:
 - Data preprocessing and feature extraction using Compute Canada.
